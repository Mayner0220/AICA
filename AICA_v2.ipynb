{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:29.046296Z",
     "start_time": "2021-04-23T14:30:29.033296Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent elements such as Tensorflow import logs, perform these tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.382501Z",
     "start_time": "2021-04-23T14:30:29.047299Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert raw files to TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.398526Z",
     "start_time": "2021-04-23T14:30:33.384469Z"
    }
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value: [str, bytes]) -> tf.train.Feature:\n",
    "    \"\"\"string / byte를 byte_list로 반환합니다.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList는 EagerTensor에서 문자열을 풀지 않습니다.\n",
    "    \n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.414524Z",
     "start_time": "2021-04-23T14:30:33.400507Z"
    }
   },
   "outputs": [],
   "source": [
    "def _float_feature(value: float) -> tf.train.Feature:\n",
    "    \"\"\"float / double를 float_list로 반환합니다.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.430504Z",
     "start_time": "2021-04-23T14:30:33.416479Z"
    }
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value: [bool, int]) -> tf.train.Feature:\n",
    "    \"\"\"bool / enum / int / uint를 int64_list로 반환합니다.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.446896Z",
     "start_time": "2021-04-23T14:30:33.432506Z"
    }
   },
   "outputs": [],
   "source": [
    "def _image_to_byte(value: str) -> bytes:\n",
    "    \"\"\"image를 bytes로 반환합니다.\"\"\"\n",
    "    raw_image = open(value, \"rb\").read()\n",
    "    return raw_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.462647Z",
     "start_time": "2021-04-23T14:30:33.448555Z"
    }
   },
   "outputs": [],
   "source": [
    "def serialize_example(raw_image: bytes, label_int: int, for_test: bool) -> tf.train.Example.SerializeToString:\n",
    "    \"\"\"\n",
    "    파일을 만들기 위해서 tf.train.Example 메시지를 만듭니다.\n",
    "    \"\"\"\n",
    "    feature = {\n",
    "        \"raw_image\": _bytes_feature(raw_image),\n",
    "        \"label\": _int64_feature(label_int),\n",
    "        \"for_test\": _int64_feature(for_test),\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:33.478766Z",
     "start_time": "2021-04-23T14:30:33.464643Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset_information(path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    데이터의 정보(이미지 경로, 라벨, 테스트용 유무)의 정보를 리스트로 정리하여 np.array로 반환합니다.\n",
    "    \"\"\"\n",
    "    raw_image, label, for_test = [], [], []\n",
    "    label_form = {\"NonDemented\": 0, \"VeryMildDemented\": 1, \"MildDemented\": 2, \"ModerateDemented\": 3}\n",
    "    \n",
    "    image_paths = glob.glob(path + \"/*/*/*.jpg\")\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image_information = image_path.split(\"\\\\\")\n",
    "        data_type, data_label = image_information[1:3]\n",
    "        \n",
    "        raw_image.append(_image_to_byte(image_path))\n",
    "        label.append(label_form[data_label])\n",
    "        for_test.append(True if data_type==\"test\" else False)\n",
    "        \n",
    "    return np.array(raw_image), np.array(label, dtype=np.int64), np.array(for_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.224291Z",
     "start_time": "2021-04-23T14:30:33.480726Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_image, label, for_test = get_dataset_information(\"./dataset\")\n",
    "\n",
    "features_dataset = tf.data.Dataset.from_tensor_slices((raw_image, label, for_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.240286Z",
     "start_time": "2021-04-23T14:30:46.225280Z"
    }
   },
   "outputs": [],
   "source": [
    "# for f0, f1, f2, f3 in features_dataset.take(1):\n",
    "#     print(f0)\n",
    "#     print(f1)\n",
    "#     print(f2)\n",
    "#     print(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.255284Z",
     "start_time": "2021-04-23T14:30:46.242281Z"
    }
   },
   "outputs": [],
   "source": [
    "def tf_serialize_example(raw_image, label_int, for_test):\n",
    "    tf_string = tf.py_function(serialize_example,\n",
    "                              (raw_image, label, for_test),\n",
    "                               tf.string)\n",
    "    return tf.reshape(tf_string, ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.319279Z",
     "start_time": "2021-04-23T14:30:46.257282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function tf_serialize_example at 0x000001E82D2F4488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function tf_serialize_example at 0x000001E82D2F4488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "serialized_features_dataset = features_dataset.map(tf_serialize_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.334280Z",
     "start_time": "2021-04-23T14:30:46.320280Z"
    }
   },
   "outputs": [],
   "source": [
    "def generator():\n",
    "    for features in features_dataset:\n",
    "        yield serialize_example(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.382285Z",
     "start_time": "2021-04-23T14:30:46.335281Z"
    }
   },
   "outputs": [],
   "source": [
    "serialized_features_dataset = tf.data.Dataset.from_generator(\n",
    "    generator, output_types=tf.string, output_shapes=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T14:30:46.603607Z",
     "start_time": "2021-04-23T14:30:46.383281Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: <tf.Tensor: shape=(), dtype=int64, numpy=2> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\nTraceback (most recent call last):\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-13-cf3ec1a35ee4>\", line 3, in generator\n    yield serialize_example(*features)\n\n  File \"<ipython-input-7-7ba49aebad3d>\", line 7, in serialize_example\n    \"label\": _int64_feature(label_int),\n\n  File \"<ipython-input-5-6aff76875256>\", line 3, in _int64_feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 542, in init\n    copy.extend(field_value)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in extend\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in <listcomp>\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\n    raise TypeError(message)\n\nTypeError: <tf.Tensor: shape=(), dtype=int64, numpy=2> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\n\n\n\t [[{{node PyFunc}}]] [Op:DatasetToTFRecord]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-10f60b3610ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./tfrecord/MRI_DATASET.tfrecord\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized_features_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\writers.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    113\u001b[0m               dataset_ops.get_legacy_output_types(dataset)))\n\u001b[0;32m    114\u001b[0m     return gen_experimental_dataset_ops.dataset_to_tf_record(\n\u001b[1;32m--> 115\u001b[1;33m         dataset._variant_tensor, self._filename, self._compression_type)  # pylint: disable=protected-access\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_experimental_dataset_ops.py\u001b[0m in \u001b[0;36mdataset_to_tf_record\u001b[1;34m(input_dataset, filename, compression_type, name)\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: TypeError: <tf.Tensor: shape=(), dtype=int64, numpy=2> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\nTraceback (most recent call last):\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 244, in __call__\n    ret = func(*args)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 827, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"<ipython-input-13-cf3ec1a35ee4>\", line 3, in generator\n    yield serialize_example(*features)\n\n  File \"<ipython-input-7-7ba49aebad3d>\", line 7, in serialize_example\n    \"label\": _int64_feature(label_int),\n\n  File \"<ipython-input-5-6aff76875256>\", line 3, in _int64_feature\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py\", line 542, in init\n    copy.extend(field_value)\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in extend\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\containers.py\", line 282, in <listcomp>\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n\n  File \"c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py\", line 171, in CheckValue\n    raise TypeError(message)\n\nTypeError: <tf.Tensor: shape=(), dtype=int64, numpy=2> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\n\n\n\t [[{{node PyFunc}}]] [Op:DatasetToTFRecord]"
     ]
    }
   ],
   "source": [
    "filename = \"./tfrecord/MRI_DATASET.tfrecord\"\n",
    "writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "writer.write(serialized_features_dataset)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
